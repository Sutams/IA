{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# first we fit the scaler on the training dataset\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# then we call the transform method to scale both the training and testing data\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_model(number_of_hidden_layers=1, number_of_neurons=2):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    model.add(Dense(number_of_neurons, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "\n",
    "    # hidden layers\n",
    "    for hidden_layer_number in range(1, number_of_hidden_layers):\n",
    "        model.add(Dense(number_of_neurons, activation='relu'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['mae',])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor # There is also a KerasClassifier class\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "# possible values of parameters - we want to find the best set of them\n",
    "# maybe it is best to create a model with 3 hidden layers, with 15 neurons in each hidden layer?\n",
    "# And maybe it would be best to create a model with 5 hidden layers, with 5 neurons in each hidden layer? \n",
    "# Let's find out!\n",
    "params = {\n",
    "      'number_of_hidden_layers': [1, 2, 3, 4, 5, 6],\n",
    "      'number_of_neurons': [8, 16, 32, 64]\n",
    "      }\n",
    "\n",
    "# Create a randomize search cross validation object, to find the best hyperparameters it will use a KFold cross validation with 4 splits\n",
    "random_search = RandomizedSearchCV(tuned_model, param_distributions = params, cv = KFold(4))\n",
    "\n",
    "# Note: RandomizedSearchCV does not check all combinations of parameters - it picks the combinations of hyperparameters to check randomly.\n",
    "# To check all possible combinations of hyperparameters, use GridSearchCV. (Computations will last longer!)\n",
    "\n",
    "# find the best parameters!\n",
    "random_search.fit(train_data, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_.get_params()\n",
    "# It was found that the best combination of hyperparameters is:\n",
    "  #  'number_of_neurons': 64\n",
    "  #  'number_of_hidden_layers': 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(tuned_model, param_grid = params, cv = KFold(4))\n",
    "\n",
    "# Note: RandomizedSearchCV does not check all combinations of parameters - it picks the combinations of hyperparameters to check randomly.\n",
    "# To check all possible combinations of hyperparameters, use GridSearchCV. (Computations will last longer!)\n",
    "\n",
    "# find the best parameters!\n",
    "grid_search.fit(train_data, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.get_params()\n",
    "# It was found that the best combination of hyperparameters is:\n",
    "  #  'number_of_neurons': 64\n",
    "  #  'number_of_hidden_layers': 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_found_model1 = build_model(6, 64)\n",
    "best_found_model2 = build_model(3,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history1 = best_found_model1.fit(train_data, train_targets, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = best_found_model2.fit(train_data, train_targets, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, (len(history1.history['mae']) + 1)), history1.history['mae'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, (len(history2.history['mae']) + 1)), history2.history['mae'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_score, test_mae_score = best_found_model1.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_score, test_mae_score = best_found_model2.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = test_data[[1, 25, 50, 75, 100]]\n",
    "predictions = best_found_model1.predict(to_predict)\n",
    "print(predictions)\n",
    "\n",
    "print(test_targets[[1, 25, 50, 75, 100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = test_data[[1, 25, 50, 75, 100]]\n",
    "predictions = best_found_model2.predict(to_predict)\n",
    "print(predictions)\n",
    "\n",
    "print(test_targets[[1, 25, 50, 75, 100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ce7a0b8043992accea837886d212becdd9412c86ff5a50f246768d9a7202fc8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
